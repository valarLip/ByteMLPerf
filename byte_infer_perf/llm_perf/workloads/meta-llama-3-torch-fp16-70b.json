{
    "model": "meta-llama-3-torch-fp16-70b",
    "test_accuracy": false,
    "test_perf": true,
    "min_new_tokens": 200,
    "max_new_tokens": 200,
    "tp_sizes": [4, 8],
    "batch_sizes": [1, 8],
    "input_tokens": [1024, 2048],
    "dataset": "llm_perf/datasets/merged_52_test.csv",
    "perf_time": 100
}